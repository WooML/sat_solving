{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WooML/sat_solving/blob/main/%EB%AF%B8%EB%8B%88%EC%BA%A1%EC%8A%A4%ED%86%A4(%EC%98%81%EC%96%B4%EB%AC%B8%EC%A0%9C_%ED%92%80%EC%9D%B4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1dLZGwNVnvK"
      },
      "source": [
        "#BERT 적용(인터넷)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flp2_v7gQgWk",
        "outputId": "3f2f9069-c1b2-458c-8f3d-0a8f48c62ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (0.3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "\n",
        "!pip install --upgrade torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWY8ZDsrQpW1",
        "outputId": "3ade4e5c-bf2e-4740-f884-d27466a8245d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.27.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3Q2-K6vDN1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4beb275-9167-4caf-a3c6-8e34e211cf12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import dill\n",
        "from copy import deepcopy\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchtext.data import Field\n",
        "from torchtext.data import TabularDataset\n",
        "from torchtext.data import BucketIterator\n",
        "from torchtext.data import Iterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0__gOVOwFFOB"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 2020\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# DATA_PATH = \"data/processed/\"\n",
        "DATA_PATH = \"/content/drive/MyDrive/미니캡스톤 자료\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewyfkEBrFFRD",
        "outputId": "0aa9bc01-27ac-4dc8-8bce-ecc8a3e501fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              context  label\n",
            "0   Competitive activities can be more than just p...      0\n",
            "1   The provision of timely, constructive feedback...      1\n",
            "2         In a sense, all competitions give feedback.      1\n",
            "3   For many, this is restricted to information ab...      1\n",
            "4   The provision of that type of feedback can be ...      1\n",
            "5   The best competitions promote excellence, not ...      1\n",
            "6   The emphasis on superiority is what we typical...      1\n",
            "7   Performance feedback requires that the program...      1\n",
            "8   Information about performance can be very help...      1\n",
            "9   People from more individualistic cultural cont...      1\n",
            "10  With this form of agency comes the belief that...      0\n",
            "11  The independent self may be more 3 driven to c...      1\n",
            "12  However, people from more interdependent cultu...      1\n",
            "13  Research has shown 4 that East Asians prefer t...      1\n",
            "14  Therefore, people 5 who hold a more interdepen...      1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/미니캡스톤 자료/sat_train1.tsv\",delimiter='\\t')\n",
        "\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##학습"
      ],
      "metadata": {
        "id": "GHu5NClr6D7q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUczGkM9VzxJ",
        "outputId": "664fd368-cd8f-4d72-9277-4b5bdcf43682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610,
          "referenced_widgets": [
            "db4a2b98c2e644248042e8ea5b2681d1",
            "442ea3b719e74e5f8aedea768ab9abee",
            "05af5bec67db46918efdb7dc0d36b991",
            "7c8a090a8289482b9bf8bde2efbc6a7b",
            "2a572d4b89e349f0acc20a58ea5078ec",
            "5401fae284ec45ebb4da25301c74c999",
            "896dbb37663f421fb132f8f9138d2ccb",
            "671c95dfb47741809c0b80b4ebaa000e",
            "3079222804ec4780a2a8fad7a255fd6c",
            "637971c618f6477f951c5b9008b275f8",
            "57d37dd7846c473e91048ca6f8cdad1b",
            "31837ffb384e4afda109c3bbdf9c06bb",
            "9fb3c69a1dc149d78cf472c787656b5d",
            "26ee52b29769498985c9f3c320c903d0",
            "64035c554c7343c295f2a5a0ba6331db",
            "c98da48459784bbd97fffb3b79425836",
            "25808bb5d32b449b8c49d6f963626f63",
            "b276cb716fa34b05aac09ef89d8178b6",
            "61056410e2a74ae3b39a2017fc34f3ee",
            "93e9feadaa9f48abbe6f92ffb19deeb1",
            "36828e9c26314dd78c20762393bc42bf",
            "1e519f4db97e4c299f971e61170aae52",
            "2a6ac1f05efb457e93ff45ae72cb7d99",
            "5f8cccfa1f274a718abde945895aa393",
            "ea0c34abfbc74397ab4c45e6eafc5778",
            "508ecdcb32154868a77dc4756963a9c7",
            "3fc7c8ca8faf475ca7d3ed2313c56c6b",
            "46e49edbbd3b4f5290340aaee779726b",
            "8bdd0ffa167d47d9b87b6fdb9091bef7",
            "65b25c04f7fa401e8148d15d29e65a43",
            "faf73419adb24785907e4e0e4e99e9fc",
            "fa780676be4748129c8259689d5fa5d4",
            "1e7f89d04d7d457eb276047f68865d2d",
            "c9404fea473f4676bbdfb5cfcf227596",
            "9afa3bc829f64b4f91e01aa815460dc0",
            "bfa48c0584614d9abde66ad19457a35b",
            "bc26795678cc417494bf719f6debeec8",
            "2f8e20042a96447d94b227f3bbc0e1d3",
            "9a5e5015859b4542b638d75c955d48e0",
            "e98eb31321f34c70a6958d7ad1bc6014",
            "135eec78a7464a03bdc37bbe68b6a73e",
            "ba5966574bd64eb6a565019cac94a3d4",
            "41b317d76ba149829f2350d8df579ead",
            "016396d8b8b747f88cb3e9b2cba41341"
          ]
        },
        "id": "XgA1a3qbXlxk",
        "outputId": "6123b255-1ca8-4dbb-8b5e-e6d4ed01e733"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db4a2b98c2e644248042e8ea5b2681d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31837ffb384e4afda109c3bbdf9c06bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a6ac1f05efb457e93ff45ae72cb7d99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9404fea473f4676bbdfb5cfcf227596"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.074541747570038\n",
            "Epoch 2, Loss: 3.175699234008789\n",
            "Epoch 3, Loss: 3.258248656988144\n",
            "Epoch 4, Loss: 2.207800179719925\n",
            "Epoch 5, Loss: 2.0708748251199722\n",
            "Epoch 6, Loss: 1.8040107786655426\n",
            "Epoch 7, Loss: 1.4440930783748627\n",
            "Epoch 8, Loss: 1.169882643967867\n",
            "Epoch 9, Loss: 0.9084118418395519\n",
            "Epoch 10, Loss: 0.7389557287096977\n",
            "Epoch 11, Loss: 0.5487607717514038\n",
            "Epoch 12, Loss: 0.4430824723094702\n",
            "Epoch 13, Loss: 0.3767631109803915\n",
            "Epoch 14, Loss: 0.3182284813374281\n",
            "Epoch 15, Loss: 0.3300452046096325\n",
            "Epoch 16, Loss: 0.26217636466026306\n",
            "Epoch 17, Loss: 0.21442247182130814\n",
            "Epoch 18, Loss: 0.23558611050248146\n",
            "Epoch 19, Loss: 0.23586584441363811\n",
            "Epoch 20, Loss: 0.2721232511103153\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class GrammarDataset(Dataset):\n",
        "    def __init__(self, sentences, labels, tokenizer, max_length):\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = str(self.sentences[idx])\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation=True\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# 데이터 준비\n",
        "grammer_dataset = pd.read_csv(\"/content/drive/MyDrive/미니캡스톤 자료/sat_train1.tsv\",delimiter='\\t')\n",
        "sentences = grammer_dataset['context']\n",
        "labels = grammer_dataset['label']\n",
        "\n",
        "# BERT 토크나이저 및 모델 로드\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# 데이터셋 및 데이터로더 생성\n",
        "max_length = 128\n",
        "batch_size = 2\n",
        "dataset = GrammarDataset(sentences, labels, tokenizer, max_length)\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# 모델 학습\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss}\")\n",
        "\n",
        "# 모델 저장 경로 정의\n",
        "model_save_path = \"/content/drive/MyDrive/미니캡스톤 자료/bert_grammar_model(20)두번째.pth\"\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model.state_dict(), model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia7QRfmx3wVb"
      },
      "source": [
        "##테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjcjnXNE6Izr",
        "outputId": "a7e14cd4-5786-409b-efa3-3310c7c6970a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hq0EC4386HVZ"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAJuY4O0330o",
        "outputId": "77f1ecf4-c173-4041-bff7-dbf3a77f02bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "# 모델 저장 경로\n",
        "model_save_path = '/content/drive/MyDrive/미니캡스톤 자료/bert_grammar_model(20)두번째.pth'\n",
        "\n",
        "# 모델 로드\n",
        "loaded_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "loaded_model.load_state_dict(torch.load(model_save_path))\n",
        "loaded_model.eval()\n",
        "\n",
        "# 테스트 문장 예측\n",
        "test_sentence = \"I plays the piano.\"\n",
        "test_encoding = tokenizer.encode_plus(\n",
        "    test_sentence,\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_length,\n",
        "    padding='max_length',\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt',\n",
        "    truncation=True\n",
        ")\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_input_ids = test_encoding['input_ids'].flatten()\n",
        "    test_attention_mask = test_encoding['attention_mask'].flatten()\n",
        "    test_outputs = model(test_input_ids.unsqueeze(0), attention_mask=test_attention_mask.unsqueeze(0))\n",
        "    predicted_label = torch.argmax(test_outputs.logits).item()\n",
        "\n",
        "\n",
        "\n",
        "if predicted_label == 0:\n",
        "    print(\"문법 오류가 있습니다.\")\n",
        "else:\n",
        "    print(\"문법 오류가 없습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##실제 문제 풀이"
      ],
      "metadata": {
        "id": "JkNT24PISUJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_problem(model_path, problem):\n",
        "    # 모델 로드\n",
        "    loaded_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "    loaded_model.load_state_dict(torch.load(model_save_path))\n",
        "    loaded_model.eval()\n",
        "\n",
        "    problem = list(map(lambda x: x.replace(\"[\", \"\").replace(\"]\", \"\"), problem))\n",
        "    tokenized_sentences = [word_tokenize(sentence) for sentence in problem]\n",
        "    sentences = []\n",
        "    for tokenized_sentence in tokenized_sentences:\n",
        "        sentences.append([TEXT.vocab.stoi[word] for word in tokenized_sentence])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        classifier.eval()\n",
        "        predict = []\n",
        "        for sentence in sentences:\n",
        "            sentence = torch.LongTensor([sentence])\n",
        "            predict += [classifier(sentence).item()]\n",
        "    answer = predict.index(min(predict)) +1\n",
        "    print(f'정답은 {answer}번 입니다')"
      ],
      "metadata": {
        "id": "JahW53GAUerN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sat_pre(sentences):\n",
        "  numbers =['①','②','③','④','⑤']\n",
        "\n",
        "  sentences = sentences.replace('!','.').replace('?','.')\n",
        "  sentences = sentences.split('.')\n",
        "  problem = [sentence for sentence in sentences if any(number in sentence for number in numbers)]\n",
        "\n",
        "  return problem"
      ],
      "metadata": {
        "id": "iRSpCdx0UqcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solving_problem(model_path,sentences):\n",
        "  problem = sat_pre(sentences)\n",
        "\n",
        "  return predict_problem(model_path,problem)"
      ],
      "metadata": {
        "id": "5XWgtBpxUwWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem_3 = '''The Greeks focus on the salient object and its attributes led to ①their failure to understand the fundamental nature of causality. Aristotle explained that a stone falling through the air is due to the stone having the property of \"gravity\". But of course a piece of wood ②tossed into waterfloats instead of sinking. This phenomenon Aristotle explained as being due to the wood having the property of\"levity\"! In both cases the focus is ③exclusively on the object, with no attention paid to the possibility thatsome force outside the object might be relevant. But the Chinese saw the world as consisting of continuously interacting substances, so their attempts to understand it ④causing them to be oriented toward the complexitiesof the entire \"field,\" that is, the context or environment as a whole. The notion ⑤that events always accour in a field of forces would have been completely intuitive to the Chinese.'''\n"
      ],
      "metadata": {
        "id": "5t5PPHijUlHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solving_problem('/content/drive/MyDrive/미니캡스톤 자료/bert_grammar_model(20)두번째.pth',problem_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1cc1cc48-f1db-4026-9ba3-dec73bc2eead",
        "id": "SRRzh3HMUyp7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-45e1d2c86bb5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msolving_problem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/미니캡스톤 자료/bert_grammar_model(20)두번째.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproblem_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-e3ba2c9f0afd>\u001b[0m in \u001b[0;36msolving_problem\u001b[0;34m(model_path, sentences)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mproblem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msat_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mpredict_problem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-06ca3ac6bf47>\u001b[0m in \u001b[0;36mpredict_problem\u001b[0;34m(model_path, problem)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_problem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mTEXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TEXT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"classifier\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dill/_dill.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, ignore, **kwds)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \"\"\"\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dill/_dill.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#NOTE: if settings change, need to update attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStockUnpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_main_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ignore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: A load persistent id instruction was encountered,\nbut no persistent_load function was specified."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U4Mn4E-qUe1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xMpm1bPlPP4"
      },
      "source": [
        "#책(파이토치 프로젝트)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##학습"
      ],
      "metadata": {
        "id": "eE8TyU0WlHjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1bBsARu2OBF",
        "outputId": "7714b4c7-3113-4b39-9ef9-270b1750132a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (0.3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "\n",
        "!pip install --upgrade torchtext==0.6.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pkmpyrm63Xkn",
        "outputId": "a5a07065-d375-4dbd-f16c-21f05dde0d6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oo0X7y5RXl0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef8a3dd3-1303-4626-b111-319d94495c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import dill\n",
        "from copy import deepcopy\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "from torchtext.data import TabularDataset\n",
        "from torchtext.data import BucketIterator\n",
        "from torchtext.data import Iterator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data import Field"
      ],
      "metadata": {
        "id": "jdLsnp1k8K_t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-7tTx9DslQ6C"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 2020\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# DATA_PATH = \"data/processed/\"\n",
        "DATA_PATH = \"/content/drive/MyDrive/미니캡스톤 자료\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# a=pd.read_csv('/content/drive/MyDrive/미니캡스톤 자료/sat_test.tsv',sep='\\t')\n",
        "# a = a[['context','label']]\n",
        "# a.to_csv('/content/drive/MyDrive/미니캡스톤 자료/sat_test1.tsv',sep='\\t',index=False)"
      ],
      "metadata": {
        "id": "qnnQaRPJ62xs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b=pd.read_csv('/content/drive/MyDrive/미니캡스톤 자료/sat_train.tsv',sep='\\t')\n",
        "# b = a[['context','label']]\n",
        "# b.to_csv('/content/drive/MyDrive/미니캡스톤 자료/sat_train1.tsv',sep='\\t',index=False)"
      ],
      "metadata": {
        "id": "-xUYH6poNs3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c=pd.read_csv('/content/drive/MyDrive/미니캡스톤 자료/sat_valid.tsv',sep='\\t')\n",
        "# c = a[['context','label']]\n",
        "# c.to_csv('/content/drive/MyDrive/미니캡스톤 자료/sat_valid1.tsv',sep='\\t',index=False)"
      ],
      "metadata": {
        "id": "uYWrwxegN0_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# d=pd.read_csv('/content/drive/MyDrive/미니캡스톤 자료/sat.csv', sep=',', encoding='cp949')\n",
        "# d = d[['context','label']]\n",
        "\n",
        "# d.to_csv('/content/drive/MyDrive/미니캡스톤 자료/sat추가.tsv', sep='\\t',index=False)"
      ],
      "metadata": {
        "id": "LkAo_pc7S3rB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxf4I7N6TgJD",
        "outputId": "f16e8c7a-caea-4269-df4b-b8325cc0752f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# b=pd.read_csv('/content/drive/MyDrive/미니캡스톤 자료/sat_train1.tsv',sep='\\t')\n",
        "# d = pd.read_csv('/content/drive/MyDrive/미니캡스톤 자료/sat추가.tsv',sep='\\t')\n",
        "\n",
        "# e = pd.concat([b,d], axis = 0)\n",
        "# e.to_csv('/content/drive/MyDrive/미니캡스톤 자료/sat_train2.tsv',sep='\\t',index=False)"
      ],
      "metadata": {
        "id": "-jdXQQZPQjl2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d=pd.read_csv('/content/drive/MyDrive/미니캡스톤 자료/sat_train2.tsv',sep='\\t',)\n",
        "d.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8IZxH2xFOFPc",
        "outputId": "cff48999-dd44-4402-dfa3-88e492472993"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  label\n",
              "0  Competitive activities can be more than just p...      0\n",
              "1  The provision of timely, constructive feedback...      1\n",
              "2        In a sense, all competitions give feedback.      1\n",
              "3  For many, this is restricted to information ab...      1\n",
              "4  The provision of that type of feedback can be ...      1"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-f3f63df6-b32e-45d7-86a8-f73afe85f9a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Competitive activities can be more than just p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The provision of timely, constructive feedback...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In a sense, all competitions give feedback.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>For many, this is restricted to information ab...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The provision of that type of feedback can be ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3f63df6-b32e-45d7-86a8-f73afe85f9a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-0606a672-4ad2-49cb-b27c-e073f79cad7e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0606a672-4ad2-49cb-b27c-e073f79cad7e')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-0606a672-4ad2-49cb-b27c-e073f79cad7e button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f3f63df6-b32e-45d7-86a8-f73afe85f9a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f3f63df6-b32e-45d7-86a8-f73afe85f9a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e=pd.read_csv('/content/drive/MyDrive/미니캡스톤 자료/cola_train.tsv',sep='\\t',)\n",
        "e.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5rvoYUcAQVwL",
        "outputId": "33bb167e-5d0d-4bf9-b68c-61bd1eb5d134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  label\n",
              "0  Our friends won't buy this analysis, let alone...      1\n",
              "1  One more pseudo generalization and I'm giving up.      1\n",
              "2   One more pseudo generalization or I'm giving up.      1\n",
              "3     The more we study verbs, the crazier they get.      1\n",
              "4          Day by day the facts are getting murkier.      1"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-eb93c2f6-28f8-40ae-ac08-02ea7d189806\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Our friends won't buy this analysis, let alone...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>One more pseudo generalization and I'm giving up.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>One more pseudo generalization or I'm giving up.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The more we study verbs, the crazier they get.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Day by day the facts are getting murkier.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb93c2f6-28f8-40ae-ac08-02ea7d189806')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-c63d658c-1a7b-463d-ad69-82641b6450cc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c63d658c-1a7b-463d-ad69-82641b6450cc')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-c63d658c-1a7b-463d-ad69-82641b6450cc button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb93c2f6-28f8-40ae-ac08-02ea7d189806 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb93c2f6-28f8-40ae-ac08-02ea7d189806');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IEGqgn3Nlejs"
      },
      "outputs": [],
      "source": [
        "#어떻게 전처리를 진행할 것인지 정의\n",
        "TEXT = Field(\n",
        "    sequential=True,  #시퀀스 데이터인지\n",
        "    use_vocab=True,   #단어 집합을 만들 것인지\n",
        "    tokenize=word_tokenize, #어떤 토큰화 함수를 쓸 것인지\n",
        "    lower=True,             #소문자화 할것인지\n",
        "    batch_first=True,       #미니 배치 차원을 맨 앞으로 해서 데이터를 불러올 것인지\n",
        ")\n",
        "LABEL = Field(\n",
        "    sequential=False,\n",
        "    use_vocab=False,\n",
        "    batch_first=True,\n",
        ")\n",
        "\n",
        "#데이터셋 만들기\n",
        "#TabularDataset:  위 필드에서 정의했던 토큰화방법으로 토큰화 수행\n",
        "cola_train_data, cola_valid_data, cola_test_data = TabularDataset.splits(\n",
        "    path=DATA_PATH,\n",
        "    train=\"cola_train.tsv\",\n",
        "    validation=\"cola_valid.tsv\",\n",
        "    test=\"cola_test.tsv\",\n",
        "    format=\"tsv\",\n",
        "    fields=[(\"text\", TEXT), (\"label\", LABEL)],\n",
        "    skip_header=1        #데이터 첫번째줄은 무시\n",
        ")\n",
        "\n",
        "#단어 집합 생성\n",
        "TEXT.build_vocab(cola_train_data, min_freq=2)\n",
        "\n",
        "#BucketIterator : 비슷한 길이의 문장들끼리 batch를 만들어 padding개수를 줄일 수 있음\n",
        "cola_train_iterator, cola_valid_iterator, cola_test_iterator = BucketIterator.splits(\n",
        "    (cola_train_data, cola_valid_data, cola_test_data),\n",
        "    batch_size=32,\n",
        "    device=None,\n",
        "    sort=False,\n",
        ")\n",
        "\n",
        "#TabularDataset:  위 필드에서 정의했던 토큰화방법으로 토큰화 수행\n",
        "sat_train_data, sat_valid_data, sat_test_data = TabularDataset.splits(\n",
        "    path=DATA_PATH,\n",
        "    train=\"sat_train2.tsv\",\n",
        "    validation=\"sat_valid1.tsv\",\n",
        "    test=\"sat_test1.tsv\",\n",
        "    format=\"tsv\",\n",
        "    fields=[(\"text\", TEXT), (\"label\", LABEL)],\n",
        "    skip_header=1\n",
        ")\n",
        "\n",
        "#BucketIterator : 비슷한 길이의 문장들끼리 batch를 만들어 padding개수를 줄일 수 있음\n",
        "sat_train_iterator, sat_valid_iterator, sat_test_iterator = BucketIterator.splits(\n",
        "    (sat_train_data, sat_valid_data, sat_test_data),\n",
        "    batch_size=8,\n",
        "    device=None,\n",
        "    sort=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95BI4TWzlepa"
      },
      "outputs": [],
      "source": [
        "# class LSTMPoolingClassifier(nn.Module):\n",
        "#     def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, pad_idx):\n",
        "#         super(LSTMPoolingClassifier, self).__init__()\n",
        "#         self.embed_layer = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=pad_idx)\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.embedding_dim = embedding_dim\n",
        "#         self.num_layers = num_layers\n",
        "#         self.ih2h = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers,\n",
        "#                             bidirectional=True, batch_first=True, dropout=0.5)\n",
        "#         self.pool2o = nn.Linear(2 * hidden_size, 1)\n",
        "#         self.sigmoid = nn.Sigmoid()\n",
        "#         self.softmax = nn.Softmax()\n",
        "#         self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.embed_layer(x)\n",
        "#         o, _ = self.ih2h(x)\n",
        "#         pool = nn.functional.max_pool1d(o.transpose(1, 2), x.shape[1])\n",
        "#         pool = pool.transpose(1, 2).squeeze()\n",
        "#         pool = self.dropout(pool)\n",
        "#         output = self.sigmoid(self.pool2o(pool))\n",
        "#         return output.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMPoolingClassifier(nn.Module):\n",
        "    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, pad_idx):\n",
        "        super(LSTMPoolingClassifier, self).__init__()\n",
        "        self.embed_layer = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        self.ih2h= nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers,\n",
        "                            bidirectional=True, batch_first=True, dropout=0.5)\n",
        "        self.pool2o = nn.Linear(2 * hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.softmax = nn.Softmax()\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.last_layer = nn.Sequential(\n",
        "            nn.Linear(2* hidden_size,1),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed_layer(x)\n",
        "        o, _ = self.ih2h(x)\n",
        "        pool = nn.functional.max_pool1d(o.transpose(1, 2), x.shape[1])\n",
        "        pool = pool.transpose(1, 2).squeeze()\n",
        "        output = self.last_layer(pool)\n",
        "        return output.squeeze()"
      ],
      "metadata": {
        "id": "fRkVy0tw_73_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "j-368jfsliHG"
      },
      "outputs": [],
      "source": [
        "def train(model: nn.Module,\n",
        "          iterator: Iterator,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          criterion: nn.Module,\n",
        "          device: str):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for _, batch in enumerate(iterator):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        text = batch.text\n",
        "        if text.shape[0] > 1:\n",
        "            label = batch.label.type(torch.FloatTensor)\n",
        "            text = text.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            output = model(text).flatten()\n",
        "            loss = criterion(output, label)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module,\n",
        "             iterator: Iterator,\n",
        "             criterion: nn.Module,\n",
        "             device: str):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for _, batch in enumerate(iterator):\n",
        "            text = batch.text\n",
        "            label = batch.label.type(torch.FloatTensor)\n",
        "            text = text.to(device)\n",
        "            label = label.to(device)\n",
        "            output = model(text).flatten()\n",
        "            loss = criterion(output, label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def test(\n",
        "    model: nn.Module,\n",
        "    iterator: Iterator,\n",
        "    device: str):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        y_real = []\n",
        "        y_pred = []\n",
        "        model.eval()\n",
        "        for batch in iterator:\n",
        "            text = batch.text\n",
        "            label = batch.label.type(torch.FloatTensor)\n",
        "            text = text.to(device)\n",
        "\n",
        "            output = model(text).flatten().cpu()\n",
        "\n",
        "            y_real += [label]\n",
        "            y_pred += [output]\n",
        "\n",
        "        y_real = torch.cat(y_real)\n",
        "        y_pred = torch.cat(y_pred)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_real, y_pred)\n",
        "    auroc = auc(fpr, tpr)\n",
        "\n",
        "    return auroc\n",
        "\n",
        "def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]  #TEXT.vocab.stoi : 단어집합내 단어 확인\n",
        "N_EPOCHS = 20\n",
        "\n",
        "lstm_pool_classifier = LSTMPoolingClassifier(\n",
        "    num_embeddings=len(TEXT.vocab),\n",
        "    embedding_dim=100,\n",
        "    hidden_size=200,\n",
        "    num_layers=4,\n",
        "    pad_idx=PAD_IDX,\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda:0\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "_ = lstm_pool_classifier.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(lstm_pool_classifier.parameters())\n",
        "bce_loss_fn = nn.BCELoss()"
      ],
      "metadata": {
        "id": "gcasob1Ni3TU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0LrnzCbSliKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbb31f8-0df3-4569-d4c5-c110c3324f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 3s\n",
            "\tTrain Loss: 0.65142\n",
            "\t Val. Loss: 0.64209\n",
            "Epoch: 02 | Time: 0m 3s\n",
            "\tTrain Loss: 0.64881\n",
            "\t Val. Loss: 0.63039\n",
            "Epoch: 03 | Time: 0m 2s\n",
            "\tTrain Loss: 0.64596\n",
            "\t Val. Loss: 0.63351\n",
            "Epoch: 04 | Time: 0m 2s\n",
            "\tTrain Loss: 0.63286\n",
            "\t Val. Loss: 0.61844\n",
            "Epoch: 05 | Time: 0m 2s\n",
            "\tTrain Loss: 0.62432\n",
            "\t Val. Loss: 0.62224\n",
            "Epoch: 06 | Time: 0m 2s\n",
            "\tTrain Loss: 0.61131\n",
            "\t Val. Loss: 0.63177\n",
            "Epoch: 07 | Time: 0m 3s\n",
            "\tTrain Loss: 0.59930\n",
            "\t Val. Loss: 0.61581\n",
            "Epoch: 08 | Time: 0m 3s\n",
            "\tTrain Loss: 0.58106\n",
            "\t Val. Loss: 0.61197\n",
            "Epoch: 09 | Time: 0m 2s\n",
            "\tTrain Loss: 0.56045\n",
            "\t Val. Loss: 0.62989\n",
            "Epoch: 10 | Time: 0m 2s\n",
            "\tTrain Loss: 0.54415\n",
            "\t Val. Loss: 0.62440\n",
            "Epoch: 11 | Time: 0m 2s\n",
            "\tTrain Loss: 0.52921\n",
            "\t Val. Loss: 0.63820\n",
            "Epoch: 12 | Time: 0m 4s\n",
            "\tTrain Loss: 0.50981\n",
            "\t Val. Loss: 0.65760\n",
            "Epoch: 13 | Time: 0m 4s\n",
            "\tTrain Loss: 0.50185\n",
            "\t Val. Loss: 0.68199\n",
            "Epoch: 14 | Time: 0m 3s\n",
            "\tTrain Loss: 0.48726\n",
            "\t Val. Loss: 0.66932\n",
            "Epoch: 15 | Time: 0m 2s\n",
            "\tTrain Loss: 0.47234\n",
            "\t Val. Loss: 0.69381\n",
            "Epoch: 16 | Time: 0m 2s\n",
            "\tTrain Loss: 0.45967\n",
            "\t Val. Loss: 0.68346\n",
            "Epoch: 17 | Time: 0m 2s\n",
            "\tTrain Loss: 0.45249\n",
            "\t Val. Loss: 0.75661\n",
            "Epoch: 18 | Time: 0m 2s\n",
            "\tTrain Loss: 0.44674\n",
            "\t Val. Loss: 0.68469\n",
            "Epoch: 19 | Time: 0m 2s\n",
            "\tTrain Loss: 0.42939\n",
            "\t Val. Loss: 0.74027\n",
            "Epoch: 20 | Time: 0m 3s\n",
            "\tTrain Loss: 0.42012\n",
            "\t Val. Loss: 0.79473\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(lstm_pool_classifier, cola_train_iterator, optimizer, bce_loss_fn, device)\n",
        "    valid_loss = evaluate(lstm_pool_classifier, cola_valid_iterator, bce_loss_fn, device)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.5f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.5f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "before_tuning_lstm_pool_classifier = deepcopy(lstm_pool_classifier)"
      ],
      "metadata": {
        "id": "hQ6JOPsnDXG1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "N_EPOCHS = 20\n",
        "\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(lstm_pool_classifier, sat_train_iterator, optimizer, bce_loss_fn, device)\n",
        "    valid_loss = evaluate(lstm_pool_classifier, sat_valid_iterator, bce_loss_fn, device)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.5f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CML939WzPYg",
        "outputId": "4096acd6-f983-429a-8ea9-01ae3d9d5050"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 0s\n",
            "\tTrain Loss: 0.71479\n",
            "\t Val. Loss: 0.63952\n",
            "Epoch: 02 | Time: 0m 0s\n",
            "\tTrain Loss: 0.58944\n",
            "\t Val. Loss: 0.35314\n",
            "Epoch: 03 | Time: 0m 0s\n",
            "\tTrain Loss: 0.45879\n",
            "\t Val. Loss: 0.34612\n",
            "Epoch: 04 | Time: 0m 0s\n",
            "\tTrain Loss: 0.48000\n",
            "\t Val. Loss: 0.29324\n",
            "Epoch: 05 | Time: 0m 0s\n",
            "\tTrain Loss: 0.40974\n",
            "\t Val. Loss: 0.26047\n",
            "Epoch: 06 | Time: 0m 0s\n",
            "\tTrain Loss: 0.37462\n",
            "\t Val. Loss: 0.18917\n",
            "Epoch: 07 | Time: 0m 0s\n",
            "\tTrain Loss: 0.42267\n",
            "\t Val. Loss: 0.16554\n",
            "Epoch: 08 | Time: 0m 0s\n",
            "\tTrain Loss: 0.41552\n",
            "\t Val. Loss: 0.15323\n",
            "Epoch: 09 | Time: 0m 0s\n",
            "\tTrain Loss: 0.36064\n",
            "\t Val. Loss: 0.15274\n",
            "Epoch: 10 | Time: 0m 0s\n",
            "\tTrain Loss: 0.39081\n",
            "\t Val. Loss: 0.12112\n",
            "Epoch: 11 | Time: 0m 0s\n",
            "\tTrain Loss: 0.36259\n",
            "\t Val. Loss: 0.10424\n",
            "Epoch: 12 | Time: 0m 0s\n",
            "\tTrain Loss: 0.27123\n",
            "\t Val. Loss: 0.07052\n",
            "Epoch: 13 | Time: 0m 0s\n",
            "\tTrain Loss: 0.39804\n",
            "\t Val. Loss: 0.04979\n",
            "Epoch: 14 | Time: 0m 0s\n",
            "\tTrain Loss: 0.36280\n",
            "\t Val. Loss: 0.04011\n",
            "Epoch: 15 | Time: 0m 0s\n",
            "\tTrain Loss: 0.32671\n",
            "\t Val. Loss: 0.03699\n",
            "Epoch: 16 | Time: 0m 0s\n",
            "\tTrain Loss: 0.40220\n",
            "\t Val. Loss: 0.03378\n",
            "Epoch: 17 | Time: 0m 0s\n",
            "\tTrain Loss: 0.30156\n",
            "\t Val. Loss: 0.02964\n",
            "Epoch: 18 | Time: 0m 0s\n",
            "\tTrain Loss: 0.32451\n",
            "\t Val. Loss: 0.02705\n",
            "Epoch: 19 | Time: 0m 0s\n",
            "\tTrain Loss: 0.34698\n",
            "\t Val. Loss: 0.02541\n",
            "Epoch: 20 | Time: 0m 0s\n",
            "\tTrain Loss: 0.30958\n",
            "\t Val. Loss: 0.02385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = before_tuning_lstm_pool_classifier.cpu()\n",
        "_ = lstm_pool_classifier.cpu()\n",
        "\n",
        "pool_sat_test_auroc = test(before_tuning_lstm_pool_classifier, sat_test_iterator, \"cpu\")\n",
        "pool_tuned_test_auroc = test(lstm_pool_classifier, sat_test_iterator, \"cpu\")\n",
        "\n",
        "print(f\"Before fine-tuning SAT Dataset Test AUROC: {pool_sat_test_auroc:.5f}\")\n",
        "print(f\"After fine-tuning SAT Dataset Test AUROC: {pool_tuned_test_auroc:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcOFN251zTQt",
        "outputId": "60bdefe4-38a3-4af6-ee50-c0aa015bd4a6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before fine-tuning SAT Dataset Test AUROC: 0.46154\n",
            "After fine-tuning SAT Dataset Test AUROC: 1.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/미니캡스톤 자료/advanced_after_tuning_model(두번째).dill\", \"wb\") as f:\n",
        "    model = {\n",
        "        \"TEXT\": TEXT,\n",
        "        \"LABEL\": LABEL,\n",
        "        \"classifier\": lstm_pool_classifier\n",
        "    }\n",
        "    dill.dump(model, f)"
      ],
      "metadata": {
        "id": "kXx5XWHSzWB0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##테스트"
      ],
      "metadata": {
        "id": "Ok4TeLg5lL8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "\n",
        "!pip install --upgrade torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfh8fUe4J-mp",
        "outputId": "095e4d22-4c4e-492c-c95a-d0ed6f09fec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.27.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9hH65hFJ9w9",
        "outputId": "7ff6f50f-772e-4cf3-8016-6ec0dabf4732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (0.3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dill\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from torchtext.data import TabularDataset\n",
        "from torchtext.data import BucketIterator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf52n1VjlPsb",
        "outputId": "583cb825-f054-4e7f-d508-3e52cd214b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 2020\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# DATA_PATH = \"data/processed/\"\n",
        "DATA_PATH = \"/content/drive/MyDrive/미니캡스톤 자료\""
      ],
      "metadata": {
        "id": "W8JzUleulPvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_problem(model_path, problem):\n",
        "    with open(model_path, \"rb\") as f:\n",
        "        model = dill.load(f)\n",
        "    TEXT = model[\"TEXT\"]\n",
        "    classifier = model[\"classifier\"]\n",
        "\n",
        "    problem = list(map(lambda x: x.replace(\"[\", \"\").replace(\"]\", \"\"), problem))\n",
        "    tokenized_sentences = [word_tokenize(sentence) for sentence in problem]\n",
        "    sentences = []\n",
        "    for tokenized_sentence in tokenized_sentences:\n",
        "        sentences.append([TEXT.vocab.stoi[word] for word in tokenized_sentence])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        classifier.eval()\n",
        "        predict = []\n",
        "        for sentence in sentences:\n",
        "            sentence = torch.LongTensor([sentence])\n",
        "            predict += [classifier(sentence).item()]\n",
        "    answer = predict.index(min(predict)) +1\n",
        "    print(f'정답은 {answer}번 입니다')"
      ],
      "metadata": {
        "id": "N8sBAledlW3o"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem_1 = [\n",
        "    \"Competitive activities can be more than just performance showcases which the best is recognized and the rest are overlooked.\",\n",
        "    \"The provision of timely, constructive feedback to participants on performance is an asset that some competitions and contests offer.\",\n",
        "    \"The provision of that type of feedback can be interpreted as shifting the emphasis to demonstrating superior performance but not necessarily excellence.\",\n",
        "    \"The emphasis on superiority is what we typically see as fostering a detrimental effect of competition.\",\n",
        "    \"Information about performance can be very helpful, not only to the participant who does not win or place but also to those who do.\",\n",
        "]\n",
        "problem_1_label = [0, 1, 1, 1, 1]"
      ],
      "metadata": {
        "id": "rn3KVhkyoKAQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_problem('/content/drive/MyDrive/미니캡스톤 자료/advanced_after_tuning_model(두번째).dill',problem_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPNZCoerlW6T",
        "outputId": "719c97fc-eea3-4b99-c57e-a86eec5fe529"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정답은 1번 입니다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "problem_2 = [\n",
        "    \"People from more individualistic cultural contexts tend to be motivated to maintain self-focused agency or control 1 as these serve as the basis of one’s self-worth.\",\n",
        "    \"With this form of agency comes the belief that individual successes 2 depending primarily on one’s own abilities and actions, and thus, whether by influencing the environment or trying to accept one’s circumstances, the use of control ultimately centers on the individual.\",\n",
        "    \"The independent self may be more 3 driven to cope by appealing to a sense of agency or control.\",\n",
        "    \"Research has shown 4 that East Asians prefer to receive, but not seek, more social support rather than seek personal control in certain cases.\",\n",
        "    \"Therefore, people 5 who hold a more interdependent self-construal may prefer to cope in a way that promotes harmony in relationships.\",\n",
        "]\n",
        "problem_2_label = [1, 0, 1, 1, 1]"
      ],
      "metadata": {
        "id": "b-P9yXRZlW9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_problem('/content/drive/MyDrive/미니캡스톤 자료/advanced_after_tuning_model.dill',problem_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRWFnIbWybpj",
        "outputId": "24147b47-0c27-4004-cbc6-2135d33a7e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정답은 2번 입니다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##실제 문제 풀이"
      ],
      "metadata": {
        "id": "-YrjfJ7hUzNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "problem_3 = '''The Greeks focus on the salient object and its attributes led to ①their failure to understand the fundamental nature of causality. Aristotle explained that a stone falling through the air is due to the stone having the property of \"gravity\". But of course a piece of wood ②tossed into waterfloats instead of sinking. This phenomenon Aristotle explained as being due to the wood having the property of\"levity\"! In both cases the focus is ③exclusively on the object, with no attention paid to the possibility thatsome force outside the object might be relevant. But the Chinese saw the world as consisting of continuously interacting substances, so their attempts to understand it ④causing them to be oriented toward the complexitiesof the entire \"field,\" that is, the context or environment as a whole. The notion ⑤that events always accour in a field of forces would have been completely intuitive to the Chinese.'''\n"
      ],
      "metadata": {
        "id": "y1NUCMCqUsrx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sat_pre(sentences):\n",
        "  numbers =['①','②','③','④','⑤']\n",
        "\n",
        "  sentences = sentences.replace('!','.').replace('?','.')\n",
        "  sentences = sentences.split('.')\n",
        "  problem = [sentence for sentence in sentences if any(number in sentence for number in numbers)]\n",
        "\n",
        "  return problem"
      ],
      "metadata": {
        "id": "7i0sMD5qUxUI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_problem(model_path, problem):\n",
        "    with open(model_path, \"rb\") as f:\n",
        "        model = dill.load(f)\n",
        "    TEXT = model[\"TEXT\"]\n",
        "    classifier = model[\"classifier\"]\n",
        "\n",
        "    problem = list(map(lambda x: x.replace(\"[\", \"\").replace(\"]\", \"\"), problem))\n",
        "    tokenized_sentences = [word_tokenize(sentence) for sentence in problem]\n",
        "    sentences = []\n",
        "    for tokenized_sentence in tokenized_sentences:\n",
        "        sentences.append([TEXT.vocab.stoi[word] for word in tokenized_sentence])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        classifier.eval()\n",
        "        predict = []\n",
        "        for sentence in sentences:\n",
        "            sentence = torch.LongTensor([sentence])\n",
        "            predict += [classifier(sentence).item()]\n",
        "    answer = predict.index(min(predict)) +1\n",
        "    print(f'정답은 {answer}번 입니다')"
      ],
      "metadata": {
        "id": "KEMlr34yWLJc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solving_problem(model_path,sentences):\n",
        "  problem = sat_pre(sentences)\n",
        "\n",
        "  return predict_problem(model_path,problem)"
      ],
      "metadata": {
        "id": "XXO7-b52Vac9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solving_problem('/content/drive/MyDrive/미니캡스톤 자료/advanced_after_tuning_model(두번째).dill',problem_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_pamQl4VN4z",
        "outputId": "c0637f0b-96b8-40d4-8c34-58c0b06ce2fb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정답은 2번 입니다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BERT(책)"
      ],
      "metadata": {
        "id": "1lbawRl3-TA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX_6zjz2Mh_e",
        "outputId": "56f99e51-306d-437a-ced0-8191889fe125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (1.23.5)\n",
            "Collecting boto3 (from pytorch-transformers)\n",
            "  Downloading boto3-1.28.25-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (4.66.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-transformers) (2023.6.3)\n",
            "Collecting sentencepiece (from pytorch-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses (from pytorch-transformers)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->pytorch-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (3.27.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->pytorch-transformers) (16.0.6)\n",
            "Collecting botocore<1.32.0,>=1.31.25 (from boto3->pytorch-transformers)\n",
            "  Downloading botocore-1.31.25-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-transformers)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->pytorch-transformers)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-transformers) (2023.7.22)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->pytorch-transformers) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.25->boto3->pytorch-transformers) (2.8.2)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->pytorch-transformers)\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->pytorch-transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->pytorch-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895240 sha256=b4354527dae7a15d55a850e11d394158819c5431a0b83630a0c71a41addd3df0\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, urllib3, sacremoses, jmespath, botocore, s3transfer, boto3, pytorch-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "Successfully installed boto3-1.28.25 botocore-1.31.25 jmespath-1.0.1 pytorch-transformers-1.2.0 s3transfer-0.6.1 sacremoses-0.0.53 sentencepiece-0.1.99 urllib3-1.26.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from pytorch_transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "3YlKwXny-XBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/미니캡스톤 자료/sat_train.tsv', sep='\\t') #구글 드라이브에서 파일 경로 복사 후 붙여넣으세요.\n",
        "valid_df = pd.read_csv('/content/drive/MyDrive/미니캡스톤 자료/sat_valid.tsv', sep='\\t') #구글 드라이브에서 파일 경로 복사 후 붙여넣으세요.\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/미니캡스톤 자료/sat_test.tsv', sep='\\t') #구글 드라이브에서 파일 경로 복사 후 붙여넣으세요."
      ],
      "metadata": {
        "id": "um98WbLrLxc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dt4j46nCOKDH",
        "outputId": "b8bab982-7e55-4fbe-9f16-262e2c8a2c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  label  year test_type  \\\n",
              "0  Competitive activities can be more than just p...      0  2021        9월   \n",
              "1  The provision of timely, constructive feedback...      1  2021        9월   \n",
              "2        In a sense, all competitions give feedback.      1  2021        9월   \n",
              "3  For many, this is restricted to information ab...      1  2021        9월   \n",
              "4  The provision of that type of feedback can be ...      1  2021        9월   \n",
              "\n",
              "   question_number                     question  answers  \n",
              "0               29  다음 글의 밑줄 친 부분 중, 어법상 틀린 것은?        1  \n",
              "1               29  다음 글의 밑줄 친 부분 중, 어법상 틀린 것은?        2  \n",
              "2               29  다음 글의 밑줄 친 부분 중, 어법상 틀린 것은?        0  \n",
              "3               29  다음 글의 밑줄 친 부분 중, 어법상 틀린 것은?        0  \n",
              "4               29  다음 글의 밑줄 친 부분 중, 어법상 틀린 것은?        3  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-9921435c-53d9-4204-be7b-2ed15273e31f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>label</th>\n",
              "      <th>year</th>\n",
              "      <th>test_type</th>\n",
              "      <th>question_number</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Competitive activities can be more than just p...</td>\n",
              "      <td>0</td>\n",
              "      <td>2021</td>\n",
              "      <td>9월</td>\n",
              "      <td>29</td>\n",
              "      <td>다음 글의 밑줄 친 부분 중, 어법상 틀린 것은?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The provision of timely, constructive feedback...</td>\n",
              "      <td>1</td>\n",
              "      <td>2021</td>\n",
              "      <td>9월</td>\n",
              "      <td>29</td>\n",
              "      <td>다음 글의 밑줄 친 부분 중, 어법상 틀린 것은?</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In a sense, all competitions give feedback.</td>\n",
              "      <td>1</td>\n",
              "      <td>2021</td>\n",
              "      <td>9월</td>\n",
              "      <td>29</td>\n",
              "      <td>다음 글의 밑줄 친 부분 중, 어법상 틀린 것은?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>For many, this is restricted to information ab...</td>\n",
              "      <td>1</td>\n",
              "      <td>2021</td>\n",
              "      <td>9월</td>\n",
              "      <td>29</td>\n",
              "      <td>다음 글의 밑줄 친 부분 중, 어법상 틀린 것은?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The provision of that type of feedback can be ...</td>\n",
              "      <td>1</td>\n",
              "      <td>2021</td>\n",
              "      <td>9월</td>\n",
              "      <td>29</td>\n",
              "      <td>다음 글의 밑줄 친 부분 중, 어법상 틀린 것은?</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9921435c-53d9-4204-be7b-2ed15273e31f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-4ca6acb3-f5d6-4b98-94d6-3b123e244b75\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ca6acb3-f5d6-4b98-94d6-3b123e244b75')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-4ca6acb3-f5d6-4b98-94d6-3b123e244b75 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9921435c-53d9-4204-be7b-2ed15273e31f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9921435c-53d9-4204-be7b-2ed15273e31f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df = train_df.sample(frac=0.1, random_state=500)\n",
        "# valid_df = valid_df.sample(frac=0.1, random_state=500)\n",
        "# test_df = test_df.sample(frac=0.1, random_state=500)"
      ],
      "metadata": {
        "id": "Wi2-jwbGLxfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Datasets(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.df.iloc[idx, 0]\n",
        "        label = self.df.iloc[idx, 1]\n",
        "        return text, label"
      ],
      "metadata": {
        "id": "zXCHyuxzLxiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Datasets(train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
        "\n",
        "valid_dataset = Datasets(valid_df)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
        "\n",
        "test_dataset = Datasets(test_df)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "fTTAEQiTLxlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66jFclHDL1vH",
        "outputId": "daf88402-ec3e-4ff4-d7b8-cd7a2843d285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 3943848.46B/s]\n",
            "100%|██████████| 433/433 [00:00<00:00, 1391673.28B/s]\n",
            "100%|██████████| 440473133/440473133 [00:09<00:00, 44604645.92B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(save_path, model, valid_loss):\n",
        "    if save_path == None:\n",
        "        return\n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "\n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(load_path, model):\n",
        "    if load_path==None:\n",
        "        return\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    return state_dict['valid_loss']\n",
        "\n",
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
        "    if save_path == None:\n",
        "        return\n",
        "    state_dict = {'train_loss_list': train_loss_list,\n",
        "                  'valid_loss_list': valid_loss_list,\n",
        "                  'global_steps_list': global_steps_list}\n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_metrics(load_path):\n",
        "    if load_path==None:\n",
        "        return\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
      ],
      "metadata": {
        "id": "UOWJ7SGvL1x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,\n",
        "          optimizer,\n",
        "          criterion = nn.BCELoss(),\n",
        "          num_epochs = 5,\n",
        "          eval_every = len(train_loader) // 2,\n",
        "          best_valid_loss = float(\"Inf\")):\n",
        "\n",
        "    total_correct = 0.0\n",
        "    total_len = 0.0\n",
        "    running_loss = 0.0\n",
        "    valid_running_loss = 0.0\n",
        "    global_step = 0\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    global_steps_list = []\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for text, label in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "            padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "\n",
        "            sample = torch.tensor(padded_list)\n",
        "            sample, label = sample.to(device), label.to(device)\n",
        "            labels = torch.tensor(label)\n",
        "            outputs = model(sample, labels=labels)\n",
        "            loss, logits = outputs\n",
        "\n",
        "            pred = torch.argmax(F.softmax(logits), dim=1)\n",
        "            correct = pred.eq(labels)\n",
        "            total_correct += correct.sum().item()\n",
        "            total_len += len(labels)\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_every == 0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    for text, label in valid_loader:\n",
        "                        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "                        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "                        sample = torch.tensor(padded_list)\n",
        "                        sample, label = sample.to(device), label.to(device)\n",
        "                        labels = torch.tensor(label)\n",
        "                        outputs = model(sample, labels=labels)\n",
        "                        loss, logits = outputs\n",
        "                        valid_running_loss += loss.item()\n",
        "\n",
        "                average_train_loss = running_loss / eval_every\n",
        "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
        "                train_loss_list.append(average_train_loss)\n",
        "                valid_loss_list.append(average_valid_loss)\n",
        "                global_steps_list.append(global_step)\n",
        "\n",
        "                running_loss = 0.0\n",
        "                valid_running_loss = 0.0\n",
        "                model.train()\n",
        "\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
        "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
        "                              average_train_loss, average_valid_loss))\n",
        "\n",
        "                if best_valid_loss > average_valid_loss:\n",
        "                    best_valid_loss = average_valid_loss\n",
        "                    save_checkpoint('/content/drive/MyDrive/미니캡스톤 자료/model.pt', model, best_valid_loss)\n",
        "                    save_metrics('/content/drive/MyDrive/미니캡스톤 자료/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "\n",
        "    save_metrics('/content/drive/MyDrive/미니캡스톤 자료/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "    print('훈련 종료!')"
      ],
      "metadata": {
        "id": "j9kO-l2SL11G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "train(model=model, optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeiKb1ruNj9Q",
        "outputId": "e042b444-d92c-4209-bc04-4fa730386a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-0bd64172102c>:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(label)\n",
            "<ipython-input-9-0bd64172102c>:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred = torch.argmax(F.softmax(logits), dim=1)\n",
            "<ipython-input-9-0bd64172102c>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(label)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [6/60], Train Loss: 0.4429, Valid Loss: 0.3779\n",
            "Model saved to ==> /content/drive/MyDrive/미니캡스톤 자료/model.pt\n",
            "Model saved to ==> /content/drive/MyDrive/미니캡스톤 자료/metrics.pt\n",
            "Epoch [1/5], Step [12/60], Train Loss: 0.4021, Valid Loss: 0.3728\n",
            "Model saved to ==> /content/drive/MyDrive/미니캡스톤 자료/model.pt\n",
            "Model saved to ==> /content/drive/MyDrive/미니캡스톤 자료/metrics.pt\n",
            "Epoch [2/5], Step [18/60], Train Loss: 0.5281, Valid Loss: 0.3781\n",
            "Epoch [2/5], Step [24/60], Train Loss: 0.3030, Valid Loss: 0.3743\n",
            "Epoch [3/5], Step [30/60], Train Loss: 0.4523, Valid Loss: 0.3626\n",
            "Model saved to ==> /content/drive/MyDrive/미니캡스톤 자료/model.pt\n",
            "Model saved to ==> /content/drive/MyDrive/미니캡스톤 자료/metrics.pt\n",
            "Epoch [3/5], Step [36/60], Train Loss: 0.4113, Valid Loss: 0.3725\n",
            "Epoch [4/5], Step [42/60], Train Loss: 0.3043, Valid Loss: 0.3734\n",
            "Epoch [4/5], Step [48/60], Train Loss: 0.5317, Valid Loss: 0.6047\n",
            "Epoch [5/5], Step [54/60], Train Loss: 0.4168, Valid Loss: 0.5097\n",
            "Epoch [5/5], Step [60/60], Train Loss: 0.3451, Valid Loss: 0.5714\n",
            "Model saved to ==> /content/drive/MyDrive/미니캡스톤 자료/metrics.pt\n",
            "훈련 종료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list, valid_loss_list, global_steps_list = load_metrics('/content/drive/MyDrive/Colab Notebooks/metrics.pt')\n",
        "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
        "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
        "plt.xlabel('Global Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0bAOcJa0L14D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for text, label in test_loader:\n",
        "            encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
        "            padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
        "\n",
        "            sample = torch.tensor(padded_list)\n",
        "            sample, label = sample.to(device), label.to(device)\n",
        "            labels = torch.tensor(label)\n",
        "            output = model(sample, labels=labels)\n",
        "\n",
        "            _, output = output\n",
        "            y_pred.extend(torch.argmax(output, 1).tolist())\n",
        "            y_true.extend(labels.tolist())\n",
        "\n",
        "    print('Classification 결과:')\n",
        "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
        "\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "    ax.xaxis.set_ticklabels(['0', '1'])\n",
        "    ax.yaxis.set_ticklabels(['0', '1'])"
      ],
      "metadata": {
        "id": "pQATkt21L8VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "best_model = model.to(device)\n",
        "load_checkpoint('/content/drive/MyDrive/Colab Notebooks/model.pt', best_model)\n",
        "evaluate(best_model, test_loader)"
      ],
      "metadata": {
        "id": "WiiMqsg6L8cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sat_pre(sentences):\n",
        "  numbers =['①','②','③','④','⑤']\n",
        "\n",
        "  sentences = sentences.replace('!','.').replace('?','.')\n",
        "  sentences = sentences.split('.')\n",
        "  problem = [sentence for sentence in sentences if any(number in sentence for number in numbers)]\n",
        "\n",
        "  return problem"
      ],
      "metadata": {
        "id": "zb8Oux-5L8fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = 'Most historians of science point to the need for a reliable calendar to regulate agricultural activity as the motivation for learning about what we now call astronomy, the study of stars and planets. Early astronomy provided information about when\n",
        "to plant crops and gave humans ① their first formal method of\n",
        "recording the passage of time. Stonehenge, the 4,000-year-old\n",
        "ring of stones in southern Britain, ② is perhaps the best-known\n",
        "monument to the discovery of regularity and predictability in\n",
        "the world we inhabit. The great markers of Stonehenge point to\n",
        "the spots on the horizon ③ where the sun rises at the solstices\n",
        "and equinoxes ― the dates we still use to mark the beginnings\n",
        "of the seasons. The stones may even have ④ been used to\n",
        "predict eclipses. The existence of Stonehenge, built by people\n",
        "without writing, bears silent testimony both to the regularity of\n",
        "nature and to the ability of the human mind to see behind\n",
        "immediate appearances and ⑤ discovers deeper meanings in\n",
        "events.'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "GpouMEaFLocV",
        "outputId": "3d8eb680-833d-4d4a-eea7-02f033dbf098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-f02bffb37ae3>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    to plant crops and gave humans ① their first formal method of\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '①' (U+2460)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sentences.replace('!','.').replace('?','.')\n",
        "sentences = sentences.split('.')\n",
        "problem = [sentence for sentence in sentences if any(number in sentence for number in numbers)]\n",
        "\n",
        "problem\n"
      ],
      "metadata": {
        "id": "Y5oXI7lSL09g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db4a2b98c2e644248042e8ea5b2681d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_442ea3b719e74e5f8aedea768ab9abee",
              "IPY_MODEL_05af5bec67db46918efdb7dc0d36b991",
              "IPY_MODEL_7c8a090a8289482b9bf8bde2efbc6a7b"
            ],
            "layout": "IPY_MODEL_2a572d4b89e349f0acc20a58ea5078ec"
          }
        },
        "442ea3b719e74e5f8aedea768ab9abee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5401fae284ec45ebb4da25301c74c999",
            "placeholder": "​",
            "style": "IPY_MODEL_896dbb37663f421fb132f8f9138d2ccb",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "05af5bec67db46918efdb7dc0d36b991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_671c95dfb47741809c0b80b4ebaa000e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3079222804ec4780a2a8fad7a255fd6c",
            "value": 231508
          }
        },
        "7c8a090a8289482b9bf8bde2efbc6a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_637971c618f6477f951c5b9008b275f8",
            "placeholder": "​",
            "style": "IPY_MODEL_57d37dd7846c473e91048ca6f8cdad1b",
            "value": " 232k/232k [00:00&lt;00:00, 3.65MB/s]"
          }
        },
        "2a572d4b89e349f0acc20a58ea5078ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5401fae284ec45ebb4da25301c74c999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896dbb37663f421fb132f8f9138d2ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "671c95dfb47741809c0b80b4ebaa000e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3079222804ec4780a2a8fad7a255fd6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "637971c618f6477f951c5b9008b275f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57d37dd7846c473e91048ca6f8cdad1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31837ffb384e4afda109c3bbdf9c06bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fb3c69a1dc149d78cf472c787656b5d",
              "IPY_MODEL_26ee52b29769498985c9f3c320c903d0",
              "IPY_MODEL_64035c554c7343c295f2a5a0ba6331db"
            ],
            "layout": "IPY_MODEL_c98da48459784bbd97fffb3b79425836"
          }
        },
        "9fb3c69a1dc149d78cf472c787656b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25808bb5d32b449b8c49d6f963626f63",
            "placeholder": "​",
            "style": "IPY_MODEL_b276cb716fa34b05aac09ef89d8178b6",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "26ee52b29769498985c9f3c320c903d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61056410e2a74ae3b39a2017fc34f3ee",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93e9feadaa9f48abbe6f92ffb19deeb1",
            "value": 28
          }
        },
        "64035c554c7343c295f2a5a0ba6331db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36828e9c26314dd78c20762393bc42bf",
            "placeholder": "​",
            "style": "IPY_MODEL_1e519f4db97e4c299f971e61170aae52",
            "value": " 28.0/28.0 [00:00&lt;00:00, 993B/s]"
          }
        },
        "c98da48459784bbd97fffb3b79425836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25808bb5d32b449b8c49d6f963626f63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b276cb716fa34b05aac09ef89d8178b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61056410e2a74ae3b39a2017fc34f3ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93e9feadaa9f48abbe6f92ffb19deeb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36828e9c26314dd78c20762393bc42bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e519f4db97e4c299f971e61170aae52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a6ac1f05efb457e93ff45ae72cb7d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f8cccfa1f274a718abde945895aa393",
              "IPY_MODEL_ea0c34abfbc74397ab4c45e6eafc5778",
              "IPY_MODEL_508ecdcb32154868a77dc4756963a9c7"
            ],
            "layout": "IPY_MODEL_3fc7c8ca8faf475ca7d3ed2313c56c6b"
          }
        },
        "5f8cccfa1f274a718abde945895aa393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46e49edbbd3b4f5290340aaee779726b",
            "placeholder": "​",
            "style": "IPY_MODEL_8bdd0ffa167d47d9b87b6fdb9091bef7",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ea0c34abfbc74397ab4c45e6eafc5778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65b25c04f7fa401e8148d15d29e65a43",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faf73419adb24785907e4e0e4e99e9fc",
            "value": 570
          }
        },
        "508ecdcb32154868a77dc4756963a9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa780676be4748129c8259689d5fa5d4",
            "placeholder": "​",
            "style": "IPY_MODEL_1e7f89d04d7d457eb276047f68865d2d",
            "value": " 570/570 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "3fc7c8ca8faf475ca7d3ed2313c56c6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46e49edbbd3b4f5290340aaee779726b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bdd0ffa167d47d9b87b6fdb9091bef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65b25c04f7fa401e8148d15d29e65a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf73419adb24785907e4e0e4e99e9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa780676be4748129c8259689d5fa5d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e7f89d04d7d457eb276047f68865d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9404fea473f4676bbdfb5cfcf227596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9afa3bc829f64b4f91e01aa815460dc0",
              "IPY_MODEL_bfa48c0584614d9abde66ad19457a35b",
              "IPY_MODEL_bc26795678cc417494bf719f6debeec8"
            ],
            "layout": "IPY_MODEL_2f8e20042a96447d94b227f3bbc0e1d3"
          }
        },
        "9afa3bc829f64b4f91e01aa815460dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a5e5015859b4542b638d75c955d48e0",
            "placeholder": "​",
            "style": "IPY_MODEL_e98eb31321f34c70a6958d7ad1bc6014",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "bfa48c0584614d9abde66ad19457a35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_135eec78a7464a03bdc37bbe68b6a73e",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba5966574bd64eb6a565019cac94a3d4",
            "value": 440449768
          }
        },
        "bc26795678cc417494bf719f6debeec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41b317d76ba149829f2350d8df579ead",
            "placeholder": "​",
            "style": "IPY_MODEL_016396d8b8b747f88cb3e9b2cba41341",
            "value": " 440M/440M [00:02&lt;00:00, 169MB/s]"
          }
        },
        "2f8e20042a96447d94b227f3bbc0e1d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a5e5015859b4542b638d75c955d48e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e98eb31321f34c70a6958d7ad1bc6014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "135eec78a7464a03bdc37bbe68b6a73e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba5966574bd64eb6a565019cac94a3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41b317d76ba149829f2350d8df579ead": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "016396d8b8b747f88cb3e9b2cba41341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}